# ðŸ§  Speech-to-Speech Translation for Indian Languages

â€œWhen machines learn to understand every voice, the world becomes truly connected.â€ ðŸŒ

### ðŸ‘¤ Author: Jenil Kalsariya  
**Institution:** Charotar University of Science and Technology (CHARUSAT)  
**Objective:** Build a multilingual **Speech-to-Speech (S2S) Translation System** for Indian languages using open-source models optimized for low-resource conditions.

---

## ðŸŒ Motivation

India is home to hundreds of languages and dialects â€” making communication across linguistic boundaries a real challenge.  
This project aims to **break language barriers** using **AI-powered speech-to-speech translation**, enabling seamless multilingual conversations.

While models like **SeamlessM4T** and **Translatotron** exist, they often perform poorly on Indian languages due to limited data.  
Hence, this project integrates **ASR (Whisper)**, **MT (NLLB-200)**, and **TTS (IndicParler-TTS)** â€” all optimized for **Indian speech and text** â€” into a unified pipeline.

---

## ðŸ§© System Pipeline

ðŸŽ¤ Input Speech (e.g., English)
â”‚
â–¼
ðŸ§  ASR â†’ Whisper (Speech â†’ Text)
â”‚
â–¼
ðŸŒ MT â†’ NLLB-200 (Text â†’ Target Language Translation)
â”‚
â–¼
ðŸ”‰ TTS â†’ IndicParler-TTS (Text â†’ Speech)
â”‚
â–¼
ðŸŽ§ Output Speech (e.g., Hindi / Tamil / Telugu)


---

## âš™ï¸ Core Components

| **Stage** | **Model** | **Framework** | **Description** |
|------------|------------|----------------|------------------|
| ðŸŽ™ï¸ ASR | **Whisper Large-V3** | PyTorch + Transformers | Converts input speech into text; supports multilingual recognition. |
| ðŸŒ MT | **facebook/nllb-200-distilled-600M** | Hugging Face Transformers | Translates recognized text into the target Indian language. |
| ðŸ”Š TTS | **ai4bharat/indic-parler-tts** | Parler-TTS | Synthesizes natural speech in target language with Indian voice characteristics. |

---

## ðŸ” Detailed Workflow

### ðŸŽ™ï¸ Step 1: Automatic Speech Recognition (ASR)
- Converts raw audio into text using **Whisper Large-V3**.
- Handles multilingual input and noisy conditions.

**Example**
Input Speech: "How are you?"
Output Text: "How are you?"


---

### ðŸŒ Step 2: Machine Translation (MT)
- Uses **NLLB-200** to translate English text into any supported Indian language.
- Optimized for 200+ languages with strong low-resource support.

**Example**

Input Text: "How are you?"
Output Text (Hindi): "à¤†à¤ª à¤•à¥ˆà¤¸à¥‡ à¤¹à¥ˆà¤‚?"


---

### ðŸ”‰ Step 3: Text-to-Speech (TTS)
- Generates expressive, human-like speech using **IndicParler-TTS**.
- Designed for accurate phoneme rendering and Indian prosody.

**Example**
Input Text: "à¤†à¤ª à¤•à¥ˆà¤¸à¥‡ à¤¹à¥ˆà¤‚?"
Output Audio: (Spoken Hindi waveform ðŸŽ§)


---

## ðŸ§  Technical Details

| **Category** | **Specification** |
|---------------|------------------|
| **Programming Language** | Python 3.10 |
| **Frameworks** | PyTorch, Hugging Face Transformers, Parler-TTS |
| **Hardware** | NVIDIA GPU (CUDA 12.x) |
| **Sampling Rate** | 16 kHz mono |
| **Supported Languages** | English, Hindi, Tamil, Telugu, Gujarati, Marathi, Bengali, etc. |

---

## ðŸ“š Datasets Used

| **Dataset** | **Purpose** | **Description** |
|--------------|-------------|-----------------|
| **FLEURS (Google)** | ASR Evaluation | Multilingual benchmark dataset for speech recognition. |
| **IndicTTS** | TTS Reference | Indian language corpus for speech synthesis. |
| **BhashaAnuvaad** | MT/ASR Training | Large-scale multilingual dataset from AI4Bharat. |
| **AI4Bharat Corpus** | TTS/MT | Additional data for fine-tuning Indian voices. |

---

## ðŸ“Š Evaluation Metrics

| **Metric** | **Component** | **Description** |
|-------------|---------------|-----------------|
| **WER (Word Error Rate)** | ASR | Measures transcription accuracy. |
| **BLEU Score** | MT | Evaluates translation fluency and adequacy. |
| **CER (Character Error Rate)** | MT | Effective for non-Latin scripts (Devanagari, Tamil, etc.). |
| **MCD (Mel Cepstral Distortion)** | TTS | Measures acoustic similarity to reference audio. |
| **F0 RMSE (Pitch Error)** | TTS | Evaluates pitch consistency and naturalness. |
| **MOS (Mean Opinion Score)** | Full Pipeline | Subjective measure of intelligibility and quality. |

---

## ðŸ§ª Experimental Results

| **Language** | **BLEU â†‘** | **CER â†“** | **MCD â†“** | **F0 RMSE â†“** | **MOS â†‘** |
|---------------|-------------|------------|-------------|----------------|------------|
| Hindi (hi) | 31.2 | 0.17 | 4.35 | 28.1 | 4.1 |
| Gujarati (gu) | 28.7 | 0.21 | 4.62 | 31.5 | 3.9 |
| Tamil (ta) | 26.4 | 0.24 | 4.78 | 33.2 | 3.8 |
| Telugu (te) | 27.1 | 0.22 | 4.55 | 29.8 | 4.0 |

> **â†‘ Higher is better**, **â†“ Lower is better**

---

## ðŸš€ Future Work

Integrate real-time S2S streaming via WebSocket.

Add prosody transfer for emotional voice matching.

Fine-tune IndicParler-TTS on conversational corpora.

Implement Translatotron-style direct S2S model.

Deploy Streamlit/Gradio web demo for multilingual use.

## ðŸ“š References

OpenAI â€” Whisper: Robust Speech Recognition via Weak Supervision

Meta AI â€” No Language Left Behind: Scaling Human-Centered Machine Translation

AI4Bharat â€” IndicParler-TTS (Hugging Face, 2025)

Google Research â€” FLEURS Multilingual Speech Dataset

AI4Bharat â€” BhashaAnuvaad Multilingual Corpus
